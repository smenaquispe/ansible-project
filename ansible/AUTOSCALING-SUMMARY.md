# Resumen: PolÃ­ticas de Autoescalamiento Personalizables

## âœ… Cambios Realizados

### ğŸ“ Variables Agregadas (`group_vars/all.yml`)

```yaml
# Perfil de autoescalamiento
autoscaling_profile: balanced # balanced u optimize-utilization

# PolÃ­ticas de autoescalamiento personalizables
cluster_autoscaler_settings:
  cpu_utilization_target: 0.7 # 70% - Escalar cuando CPU > 70%
  memory_utilization_target: 0.8 # 80% - Escalar cuando memoria > 80%
  scale_down_delay_after_add: 600 # 10 min - Espera antes de escalar abajo
  scale_down_unneeded_time: 600 # 10 min - Tiempo subutilizado antes de remover
  scale_down_utilization_threshold: 0.5 # 50% - Umbral para considerar subutilizado
```

### ğŸ”§ Playbooks Actualizados

1. **`create-cluster.yml`**

   - âœ… Agregado soporte para `autoscaling_profile`
   - âœ… Agregado `cluster_autoscaling` con lÃ­mites de recursos
   - âœ… Agregado `resource_limits` para CPU y memoria
   - âœ… Display mejorado mostrando configuraciÃ³n de autoescalamiento

2. **`update-cluster.yml`**
   - âœ… Mismo soporte que create-cluster.yml
   - âœ… Permite actualizar polÃ­ticas sin recrear el cluster

### ğŸ“š DocumentaciÃ³n Nueva

- **`AUTOSCALING.md`** - GuÃ­a completa de configuraciÃ³n de autoescalamiento

## ğŸ¯ CÃ³mo Usar

### 1. Configurar PolÃ­ticas Personalizadas

Edita `ansible/group_vars/all.yml`:

```yaml
# Ejemplo: Escalar cuando CPU > 60%
cluster_autoscaler_settings:
  cpu_utilization_target: 0.6 # 60%
  memory_utilization_target: 0.75 # 75%

min_nodes: 2
max_nodes: 8
autoscaling_profile: balanced
```

### 2. Crear Cluster con PolÃ­ticas

```bash
ansible-playbook -i ansible/inventory/hosts ansible/playbooks/create-cluster.yml
```

### 3. Actualizar PolÃ­ticas en Cluster Existente

```bash
# Edita group_vars/all.yml y luego:
ansible-playbook -i ansible/inventory/hosts ansible/playbooks/update-cluster.yml
```

### 4. Override en Runtime

```bash
# Cambiar solo para esta ejecuciÃ³n
ansible-playbook -i ansible/inventory/hosts ansible/playbooks/create-cluster.yml \
  -e "autoscaling_profile=optimize-utilization" \
  -e '{"cluster_autoscaler_settings": {"cpu_utilization_target": 0.8}}'
```

## ğŸ“Š ComparaciÃ³n: Antes vs Ahora

### âŒ Antes

```yaml
# Solo podÃ­as configurar cantidad de nodos
min_nodes: 2
max_nodes: 5
# No habÃ­a control sobre CUÃNDO escalar
# GKE usaba valores por defecto (60% CPU)
```

### âœ… Ahora

```yaml
# Controlas cantidad de nodos
min_nodes: 2
max_nodes: 5

# Y ADEMÃS controlas CUÃNDO escalar
cluster_autoscaler_settings:
  cpu_utilization_target: 0.7 # TÃš decides el umbral
  memory_utilization_target: 0.8
  scale_down_utilization_threshold: 0.5

# Y el perfil de comportamiento
autoscaling_profile: balanced
```

## ğŸ“ Ejemplos PrÃ¡cticos

### AplicaciÃ³n con Picos de CPU

Tu aplicaciÃ³n tiene picos de CPU repentinos:

```yaml
cluster_autoscaler_settings:
  cpu_utilization_target: 0.6 # Escalar temprano (60%)
  memory_utilization_target: 0.8
  scale_down_delay_after_add: 900 # Esperar 15 min antes de escalar abajo

min_nodes: 3 # Mantener capacidad base
max_nodes: 10
autoscaling_profile: balanced
```

### AplicaciÃ³n con Uso Estable (Ahorro de Costos)

Tu aplicaciÃ³n tiene carga predecible:

```yaml
cluster_autoscaler_settings:
  cpu_utilization_target: 0.8 # Tolerar mÃ¡s uso (80%)
  memory_utilization_target: 0.85
  scale_down_delay_after_add: 300 # Escalar abajo rÃ¡pido (5 min)
  scale_down_unneeded_time: 300
  scale_down_utilization_threshold: 0.4 # Remover nodos subutilizados

min_nodes: 1 # MÃ­nimo posible
max_nodes: 5
autoscaling_profile: optimize-utilization # Priorizar ahorro
```

### AplicaciÃ³n CrÃ­tica (Alta Disponibilidad)

No puedes tolerar latencia por falta de recursos:

```yaml
cluster_autoscaler_settings:
  cpu_utilization_target: 0.5 # Escalar muy temprano (50%)
  memory_utilization_target: 0.6
  scale_down_delay_after_add: 1200 # Esperar 20 min
  scale_down_unneeded_time: 1200
  scale_down_utilization_threshold: 0.3 # Solo remover si MUY subutilizado

min_nodes: 4 # Capacidad base alta
max_nodes: 15
autoscaling_profile: balanced
```

## ğŸ” Monitoreo

### Ver ConfiguraciÃ³n Aplicada

```bash
# Ver cluster completo
gcloud container clusters describe todo-app-cluster --zone=us-central1-a

# Ver solo autoescalamiento
gcloud container clusters describe todo-app-cluster \
  --zone=us-central1-a \
  --format="yaml(autoscaling)"
```

### Ver Comportamiento en Tiempo Real

```bash
# Ver uso de recursos de nodos
kubectl top nodes

# Ver uso de recursos de pods
kubectl top pods -n todo-app

# Ver eventos de autoescalamiento
kubectl get events --all-namespaces | grep -i scale
```

## ğŸ“ˆ Entendiendo los Umbrales

### `cpu_utilization_target: 0.7` (70%)

**Significado:** Cuando tus pods usan el 70% del CPU solicitado (`requests`), GKE agrega un nodo.

**Ejemplo:**

```yaml
# En tu deployment
resources:
  requests:
    cpu: 500m # Cada pod pide 500 milicores

# Si tienes 4 pods (4 * 500m = 2000m = 2 CPUs solicitados)
# GKE escalarÃ¡ cuando el uso real sea > 70% de 2 CPUs = 1.4 CPUs
```

**Valores sugeridos por escenario:**

- **0.5-0.6** (50-60%): Aplicaciones crÃ­ticas, alta disponibilidad
- **0.7-0.8** (70-80%): Balance general (recomendado)
- **0.8-0.9** (80-90%): OptimizaciÃ³n de costos

### `scale_down_utilization_threshold: 0.5` (50%)

**Significado:** Un nodo se puede remover si usa menos del 50% de sus recursos.

**Ejemplo:**

```yaml
# Nodo con 2 CPUs y 4 GB RAM
# Si los pods en ese nodo usan:
#   - 0.8 CPUs (40%)
#   - 1.5 GB RAM (37.5%)
# GKE puede remover este nodo (estÃ¡ por debajo del 50%)
```

## âš ï¸ Importante: Diferencia con `gcp_compute_autoscaler`

El mÃ³dulo `gcp_compute_autoscaler` que viste en la documentaciÃ³n es para **Compute Engine Instance Groups** (VMs normales), NO para GKE.

Para GKE, el autoescalamiento se configura directamente en el cluster con `gcp_container_cluster`, que es lo que implementamos.

## ğŸš€ Beneficios

1. âœ… **Control Total**: Decides exactamente cuÃ¡ndo escalar
2. âœ… **OptimizaciÃ³n de Costos**: Ajusta para usar menos recursos
3. âœ… **Mejor Performance**: Escalar antes de que haya problemas
4. âœ… **Flexibilidad**: Cambia polÃ­ticas sin recrear el cluster
5. âœ… **Transparente**: Todo en variables, fÃ¡cil de entender y modificar

## ğŸ“š DocumentaciÃ³n

Lee `ansible/AUTOSCALING.md` para:

- ExplicaciÃ³n detallada de cada parÃ¡metro
- MÃ¡s ejemplos de configuraciÃ³n
- Mejores prÃ¡cticas
- GuÃ­as de monitoreo
- Troubleshooting

## ğŸ‰ Resultado Final

Ahora puedes controlar completamente el autoescalamiento de tu cluster GKE modificando simplemente las variables en `group_vars/all.yml`:

```yaml
# Â¿Quieres escalar con menos CPU? Cambia esto:
cpu_utilization_target: 0.6 # Era 0.7, ahora 60%

# Â¿Quieres optimizar costos? Cambia esto:
autoscaling_profile: optimize-utilization # Era balanced

# Â¿Quieres mÃ¡s nodos? Cambia esto:
max_nodes: 10 # Era 5

# Y aplica los cambios:
# ansible-playbook playbooks/update-cluster.yml
```

Â¡Todo completamente configurable y documentado! ğŸš€
